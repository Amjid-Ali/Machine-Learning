{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics for Regression Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are Evaluation Metrics?\n",
    "Evaluation Metrics are used to measure the quality of a Machine Learning algorithm. There are many evaluation metrics present for different types of algorithms. We will be discussing about the evaluation metrics for Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics for Machine Learning Regression Algorithms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Absolute Error\n",
    "# Mean Square Error\n",
    "# Root Mean Square Error\n",
    "# R² Score\n",
    "# Adjusted R² Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Absolute Error \n",
    "Mean Absolute Error is the average of the sum of absolute difference between the actual values and the predicted values. Mean Absolute Error is not sensitive to outliers. MAE should be used when you are solving a regression problem and don’t want outliers to play a big role in the prediction. It can be useful if you know that the distribution of data is multimodal.\n",
    "\n",
    "\n",
    "![title](meanabsoluteerror.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"./Housing.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=pd.get_dummies(dataset.drop('price',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=dataset.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(features,label,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LinearRegression()\n",
    "model.fit(features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions over test data\n",
    "predictions = model.predict(X_test)\n",
    "# Evaluating the model using MAE Evaluation Metric\n",
    "# print(mean_absolute_error(y_test, predictions))\n",
    "train_test=model.predict(X_train)\n",
    "# print(train_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Root Mean Square Error (RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Square Error is the average of the sum of square of the difference between actual and predicted values.\n",
    "\n",
    "MSE is most useful when the dataset contains outliers, or unexpected values (too high or too low values). So, it should be taken into consideration that if our model makes a single very bad prediction MSE magnifies the error.\n",
    "\n",
    "MSE is least useful when a single bad prediction would ruin the entire model’s predicting abilities, i.e. when the dataset contains a lot of noise.\n",
    "\n",
    "The MSE has the units squared of whatever is plotted on vertical axis or y-axis. Since square of the error is taken in the function.\n",
    "\n",
    "A large MSE value means that the data values are dispersed widely around the mean of the data and a small MSE value means that the data values are closely dispersed around the mean. i.e. A model with small MSE value has better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](meansquareerror.jpeg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1298240740572.5562\n",
      "1298240740572.5562\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Defining our own MSE function\n",
    "def own_mean_squared_error(actual, predictions):\n",
    "    return ((predictions - actual) ** 2).mean()\n",
    "# Initializing the model and fitting the model with train data\n",
    "model = RandomForestRegressor(\n",
    "               n_estimators = 100,\n",
    "               criterion = 'mse'\n",
    "        )\n",
    "model.fit(X_train,y_train)\n",
    "# Generating predictions over test data\n",
    "predictions = model.predict(X_test)\n",
    "# Evaluating the model using MSE Evaluation Metric\n",
    "print(mean_squared_error(y_test, predictions))\n",
    "print(own_mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Root Mean Square Error (RMSE)\n",
    "Root Mean Square Error is same as Mean Square Error but root of the MSE is considered while evaluating the model. \n",
    "\n",
    "RMSE is more sensitive to the presence of false data .i.e. outliers. RMSE is most useful when large errors are present and they drastically effect the model performance. Since, RMSE assigns a higher weights to large errors.\n",
    "\n",
    "RMSE is a frequently used evaluation metric for evaluating a model. Unlike MSE, Root Mean Square Error has the same unit of \n",
    "quantity plotted on vertical axis or y-axis. Since square root of the MSE value is taken in RMSE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](rmse.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1117224.6511898544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Defining RMSE function\n",
    "def root_mean_squared_error(actual, predictions):\n",
    "    return np.sqrt(mean_squared_error(actual, predictions))\n",
    "# Initializing the model and fitting the model with train data\n",
    "model = RandomForestRegressor(\n",
    "               n_estimators = 100,\n",
    "               criterion = 'mse'\n",
    "        )\n",
    "model.fit(X_train,y_train)\n",
    "# Generating predictions over test data\n",
    "predictions = model.predict(X_test)\n",
    "# Evaluating the model using RMSE Evaluation Metric\n",
    "print(root_mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R² Score\n",
    "R² score also known as the coefficient of determination gives the measure of how good a model fits to a given dataset. It indicates how closer are the predicted values to the actual values.\n",
    "\n",
    "![title](r2.png)\n",
    "\n",
    "\n",
    "Let’s breakdown the formula and look into each term:\n",
    "SSᵣₑₛ = Sum of Square of Residuals\n",
    "SSₜₒₜ = Total Sum of Squares\n",
    "The R² value ranges from -∞ to 1. A model with negative R² value indicates that the best fit line is performing worse than the average fit line.\n",
    "Let us look into the implementation for R² evaluation metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7037462895672345\n"
     ]
    }
   ],
   "source": [
    "# Importing all necessary libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "# Initializing the model and fitting the model with train data\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "# Generating predictions over test data\n",
    "predictions = model.predict(X_test)\n",
    "# Evaluating the model using R² Evaluation Metric\n",
    "print(r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# draw back of r2\n",
    "The major drawback of the R² metric is that, as the number of input features for the model increases the R² value also increases irrespective of the significance of the added feature with respect to output variable. i.e. even if the added feature has no correlation with the output variable, the R² value increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adjusted R2\n",
    "Adjusted R² is a modified form of R² that penalizes the addition of new independent variable or predictor and only increases if the new independent variable or predictor enhances the model performance.\n",
    "\n",
    "![title](adj_r2.png)\n",
    "\n",
    "\n",
    "Let us breakdown the formula and look into its each term:\n",
    "R² : It is R² Score\n",
    "n : Number of Samples in our Dataset\n",
    "k : Number of Predictors\n",
    "There is no inbuilt function to calculate only adjusted R². Let us look into the implementation part of Adjusted R²:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6364159008325151"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Importing all necessary libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "# Defining the adjusted R² function\n",
    "def adjusted_r2_score(actual, predictions, num_pred, num_samples):\n",
    "    n = num_samples\n",
    "    k = num_pred\n",
    "    r2 = r2_score(actual, predictions)\n",
    "    adjusted_r2 = 1 - ((1-r2) * ((n-1)/(n-k-1)))\n",
    "    return adjusted_r2\n",
    "# Initializing the model and fitting the model with train data\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "# Generating predictions over test data\n",
    "predictions = model.predict(X_test)\n",
    "# Evaluating the model using Adjusted R² Evaluation Metric\n",
    "num_samples = X_test.shape[0]\n",
    "num_predictors = X_test.shape[1]\n",
    "adjusted_r2_score(y_test, predictions, num_predictors, num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# note \n",
    "Note: Adjusted R² will be always less than or equal to R² Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
